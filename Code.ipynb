{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b40c703-56eb-4ee0-9d36-92e9d13e0c90",
   "metadata": {},
   "source": [
    "### Install libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68533f61-7b4f-4faa-a820-096c90066160",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this code \n",
    "!pip install selenium\n",
    "!pip install webdriver-manager\n",
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff19110-9437-41e8-9000-4d7f5d02b871",
   "metadata": {},
   "source": [
    "### Scraping data\n",
    "Run the code below for scraping the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a9172f-8ce9-42bf-8c15-059cacc6c723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Browser Closed!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.edge.service import Service as EdgeService\n",
    "from webdriver_manager.microsoft import EdgeChromiumDriverManager\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "options=webdriver.EdgeOptions()\n",
    "options.add_experimental_option('detach', True)\n",
    "driver = webdriver.Edge(service=EdgeService(EdgeChromiumDriverManager().install()), options=options)\n",
    "actions = ActionChains(driver)\n",
    "# driver.maximize_window()\n",
    "\n",
    "\n",
    "url= \"https://\"\n",
    "driver.get(url)\n",
    "time.sleep(3)\n",
    "\n",
    "# Locating Arrow to navigate to next page (You can Inspect the page Arrow from page, copy xpath and paste here)\n",
    "locate_arrow=driver.find_element(By.XPATH, '//*[@id=\"pbiAppPlaceHolder\"]/report-embed/div/div[2]/logo-bar/div/div/div/logo-bar-navigation/span/button[2]')\n",
    "for i in range(3):           # Navigating to 4th page\n",
    "    click_button=locate_arrow.click();\n",
    "    if i==2:\n",
    "        time.sleep(2)\n",
    "time.sleep(6)\n",
    "\n",
    "\n",
    "# Click at dropdown\n",
    "dropdown = driver.find_element(By.XPATH, '//*[@id=\"pvExplorationHost\"]/div/div/exploration/div/explore-canvas/div/div[2]/div/div[2]/div[2]/visual-container-repeat/visual-container[3]/transform/div/div[3]/div/div/visual-modern/div/div/div[2]/div/i')\n",
    "driver.execute_script(\"arguments[0].click();\", dropdown);\n",
    "time.sleep(2)\n",
    "\n",
    "\n",
    "\n",
    "# Define the number of iterations (how many times you want to perform the action)\n",
    "num_iterations = 50000  # Adjust as needed\n",
    "scraped_data = []\n",
    "try:\n",
    "    for _ in range(num_iterations):\n",
    "        actions.send_keys(Keys.ARROW_DOWN).perform()\n",
    "        time.sleep(1)\n",
    "        actions.send_keys(Keys.RETURN).perform()\n",
    "        time.sleep(1)\n",
    "    \n",
    "        # Find and extract the data from the web page\n",
    "        line = driver.find_element(By.CLASS_NAME, 'slicer-restatement').text\n",
    "        row = driver.find_element(By.CLASS_NAME, 'card').text\n",
    "    \n",
    "        # Append the scraped data to the list\n",
    "        scraped_data.append({'Ids': line, 'OTG': row})\n",
    "    \n",
    "\n",
    "except Exception as e:\n",
    "    print(\"Browser Closed!, run the below code now and open csv to check the output.\")\n",
    "\n",
    "finally:\n",
    "    \n",
    "    driver.quit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380d0ab3-7f40-46eb-a39b-35c0862047d5",
   "metadata": {},
   "source": [
    "### Save the data into CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5773c156-0023-42d5-841b-9c9ca9580c53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to 'scraped_data.csv'\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "csv_filename = 'scraped_data.csv'\n",
    "with open(csv_filename, 'w', newline='') as csvfile:\n",
    "    fieldnames = ['Ids', 'OTG']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    \n",
    "    # Write the header\n",
    "    writer.writeheader()\n",
    "    \n",
    "    # Write the data\n",
    "    for data in scraped_data:\n",
    "        writer.writerow(data)\n",
    "\n",
    "print(f\"Data saved to '{csv_filename}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a3da25-7f4b-447c-9693-1ee799dbc7dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
